{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.tensor import Tensor\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "import warnings\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from hofer import UpperDiagonalThresholdedLogTransform, prepare_batch, SLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hofer Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping dim0 diagrams for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim0_files = glob('./barcodes/dim0/*.npy')\n",
    "trans = UpperDiagonalThresholdedLogTransform(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_and_tensored = [trans(torch.tensor(np.load(d))) for d in dim0_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, dummy, max_points, batch = prepare_batch(transformed_and_tensored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving dim0 diamgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, d in enumerate(dim0_files):\n",
    "    np.save(d.replace('/dim0/', '/dim0_vector/'), X[ix, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./barcodes/dim0_vector/dummy', dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping dim1 diagrams for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim1_files = glob('./barcodes/dim1/*.npy')\n",
    "trans = UpperDiagonalThresholdedLogTransform(.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_and_tensored_dim1 = [trans(torch.tensor(np.load(d))) for d in dim1_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dim1, dummy_dim1, max_point_dim1, batch_dim1 = prepare_batch(transformed_and_tensored_dim1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving dim0 diamgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, d in enumerate(dim1_files):\n",
    "    np.save(d.replace('/dim1/', '/dim1_vector/'), X_dim1[ix, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./barcodes/dim1_vector/dummy', dummy_dim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1175, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('./barcodes/dim1_vector/1989_02_SIN_data_dim1.npy').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirming Data Pipeline is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(torch.tensor([1,2]), dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    data[data == -1] = 0\n",
    "    data[143:167, 223:247][data[143:167, 223:247] == 0] = 1\n",
    "    return data \n",
    "\n",
    "def resize_data(data):\n",
    "    im = Image.fromarray(np.uint8(cm.gist_earth(data, alpha=None)*255)[:, :, :3])\n",
    "    resized_data = np.array(im.resize((112, 76)).convert('L'))\n",
    "    return resized_data/resized_data.max()\n",
    "\n",
    "# class SeaIceDataset(Dataset):\n",
    "    \n",
    "#     def __init__(self, seq_len, data_folder='./data/*.pkl', return_dims=False, dim0_folder='dim0_vector', dim1_folder='dim1_vector'):\n",
    "#         self.seq_len = seq_len\n",
    "#         self.data_files = glob(data_folder)\n",
    "#         self.return_dims = return_dims\n",
    "#         self.dim0_folder = dim0_folder\n",
    "#         self.dim1_folder = dim1_folder\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.data_files) - (self.seq_len + 1)\n",
    "    \n",
    "#     def __getitem__(self, ix):\n",
    "#         X = np.array([resize_data(clean_data(np.array(np.load(d)))) for d in self.data_files[ix:ix+self.seq_len]], dtype=np.float32)\n",
    "#         y = resize_data(clean_data(np.load(self.data_files[ix+self.seq_len+1]))).flatten().astype(np.float32)\n",
    "        \n",
    "#         if self.return_dims:\n",
    "#             dim0 = np.array([np.load('./barcodes/{}/{}'.format(self.dim0_folder, d.split('/')[-1].split('.')[0] + '_dim0.npy')) for d in self.data_files[ix:ix+self.seq_len]], dtype=np.float32)\n",
    "#             dim1 = np.array([np.load('./barcodes/{}/{}'.format(self.dim1_folder, d.split('/')[-1].split('.')[0] + '_dim1.npy')) for d in self.data_files[ix:ix+self.seq_len]], dtype=np.float32)\n",
    "#             return X, dim0, dim1, y\n",
    "#         else:\n",
    "#             return X, y\n",
    "\n",
    "\n",
    "class SeaIceDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, seq_len, data_folder='./data/*.pkl', return_dims=False):\n",
    "        self.seq_len = seq_len\n",
    "        self.data_files = glob(data_folder)\n",
    "        self.return_dims = return_dims\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_files) - (self.seq_len + 1)\n",
    "    \n",
    "    def __getitem__(self, ix):\n",
    "        X = np.array([resize_data(clean_data(np.array(np.load(d)))) for d in self.data_files[ix:ix+self.seq_len]], dtype=np.float32)\n",
    "        y = resize_data(clean_data(np.load(self.data_files[ix+self.seq_len+1]))).flatten().astype(np.float32)\n",
    "        \n",
    "        if self.return_dims:\n",
    "            trans = UpperDiagonalThresholdedLogTransform(.1)\n",
    "            # Read in the dim0, and dim1 data.\n",
    "            dim0 = [trans(torch.tensor(np.load('./barcodes/dim0/{}'.format(d.split('\\\\')[-1].split('.')[0] + '_dim0.npy')))) for d in self.data_files[ix:ix+self.seq_len]]\n",
    "            dim1 = [trans(torch.tensor(np.load('./barcodes/dim1/{}'.format(d.split('\\\\')[-1].split('.')[0] + '_dim1.npy')))) for d in self.data_files[ix:ix+self.seq_len]]\n",
    "            return X, dim0, dim1, y\n",
    "        else:\n",
    "            return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 3; batch_size = 2\n",
    "si_dataset = SeaIceDataset(seq_length, return_dims=False)\n",
    "train_loader = DataLoader(si_dataset, shuffle=True, batch_size=batch_size, num_workers=0, drop_last=True)#, collate_fn=collation_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 76, 112])\n",
      "torch.Size([2, 8512])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2, 3, X, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.7071,  0.7071],\n",
       "         [ 0.7071,  0.7071],\n",
       "         [ 0.7071,  0.7071],\n",
       "         ...,\n",
       "         [10.6066, 10.6066],\n",
       "         [14.3179, 14.3179],\n",
       "         [70.7107, 70.7107]]), tensor([[ 0.7071,  0.7071],\n",
       "         [ 0.7071,  0.7071],\n",
       "         [ 0.7071,  0.7071],\n",
       "         ...,\n",
       "         [13.9463, 13.9463],\n",
       "         [14.5602, 14.5602],\n",
       "         [70.7107, 70.7107]]), tensor([[ 0.7071,  0.7071],\n",
       "         [ 0.7071,  0.7071],\n",
       "         [ 0.7071,  0.7071],\n",
       "         ...,\n",
       "         [ 7.2801,  7.2801],\n",
       "         [10.5119, 10.5119],\n",
       "         [70.7107, 70.7107]])]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YEET[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-110-aef61829cf62>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-110-aef61829cf62>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    [1,2,3,4,4]*\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[1,2,3,4,4]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collation_station(batch):\n",
    "    X = torch.stack([torch.from_numpy(b[0]) for b in batch], 0)\n",
    "    y = torch.stack([torch.from_numpy(b[-1]) for b in batch], 0)\n",
    "    dim0_batch = []\n",
    "    dim1_batch = []\n",
    "    for b in batch:\n",
    "        dim0_batch += b[1]\n",
    "        dim1_batch += b[2]\n",
    "    dim0 = prepare_batch(dim0_batch)\n",
    "    dim1 = prepare_batch(dim1_batch)\n",
    "    return X, dim0, dim1, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 3; batch_size = 2\n",
    "si_dataset = SeaIceDataset(seq_length, return_dims=True)\n",
    "train_loader = DataLoader(si_dataset, shuffle=True, batch_size=batch_size, num_workers=0, drop_last=True, collate_fn=collation_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim0[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, dim0, dim1, y in train_loader:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
